{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a detailed walkthrough for analyzing pySCENIC + scRNA-seq data. It is intended to be ran without much modification to the code, however, the file architecture will be different depending on use case. In addition, cistarget databases and transcription factor databases will vary as well. Consider the goal of the analysis and use this workflow as a guideline.\n",
    "\n",
    "\n",
    "\n",
    "**TLDR:** Use this as a guideline. For the most part, variables declared '...' are marked for user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, glob\n",
    "import pickle\n",
    "import sys\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "import matplotlib.pyplot as plt\n",
    "from arboreto.utils import load_tf_names\n",
    "from arboreto.algo import grnboost2\n",
    "import louvain\n",
    "import leidenalg\n",
    "from pyscenic.utils import modules_from_adjacencies\n",
    "from pyscenic.prune import prune2df, df2regulons\n",
    "from pyscenic.aucell import aucell\n",
    "import loompy\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file architecture will be dependent on use case. However, it's important to keep note of what files are required for this analysis:\n",
    "\n",
    "1. Single cell expression data (either .csv or .loom) \n",
    "2. A csv of adjecensies from the pySCENIC GRN step.\n",
    "3. A csv of regulons from the pySCENIC ctx step.\n",
    "4. A file of known TFs for target organism. One TF per line of the .txt file. (http://bioinfo.life.hust.edu.cn/AnimalTFDB4/#/Download) \n",
    "5. From cisTarget database you'll need a genome ranking database (.feather) and motif annotation database (https://resources.aertslab.org/cistarget/) \n",
    "    -  I take two .feather files , one for centered region around TSS and one for upstream of TSS. cisTarget has instructions for navigating the database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define File architecture\n",
    "PROJECT_FOLDER=\"...\"\n",
    "DATABASE_FOLDER = \"...\"\n",
    "INPUT_FOLDER = \"...\"\n",
    "ADJACENCIES_FOLDER = \"...\"\n",
    "\n",
    "#Change to where your output files are from pyscenic cli steps\n",
    "REGULONS_FOLDER = \"...\"\n",
    "AUCELL_FOLDER = \"...\"\n",
    "\n",
    "DATABASES_GLOB = os.path.join(DATABASE_FOLDER, \"...\")\n",
    "MOTIF_ANNOTATIONS_FNAME = os.path.join(DATABASE_FOLDER, \"...\")\n",
    "\n",
    "MM_TFS_FNAME = os.path.join(DATABASE_FOLDER, '...')\n",
    "SC_EXP_FNAME = os.path.join(INPUT_FOLDER, \"...\")\n",
    "\n",
    "ADJACENCIES_FNAME = os.path.join(ADJACENCIES_FOLDER, \"...\")\n",
    "REGULONS_FNAME = os.path.join(REGULONS_FOLDER, \"...\")\n",
    "\n",
    "# If running aucell on CLI, define location below. Currently, the pipeline runs aucell within itself as it doesn't take very long. [OPTIONAL]\n",
    "AUC_FNAME = os.path.join(AUCELL_FOLDER, \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with the expression data info from the input loom file \n",
    "ex_matrix = anndata.read_loom(SC_EXP_FNAME)\n",
    "\n",
    "# Convert to a pd dataframe\n",
    "ex_matrix = anndata.AnnData.to_df(ex_matrix)\n",
    "\n",
    "# Visualize the data, it should have cells as rows and genes as columns. Also check dimensions for data loss. \n",
    "ex_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll do some initial processing to create an adata object and prep it for later integration and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate expression dataframe\n",
    "def is_valid_exp_matrix(mtx):\n",
    "    return (all(isinstance(idx, str) for idx in mtx.index) \n",
    "            and all(isinstance(idx, str) for idx in mtx.columns)\n",
    "            and (mtx.index.nlevels == 1)\n",
    "            and (mtx.columns.nlevels == 1))\n",
    "is_valid_exp_matrix(ex_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scanpy Settings can be changed given user preference.\n",
    "sc.settings.verbosity = 3 \n",
    "sc.logging.print_header()\n",
    "sc.settings.set_figure_params(dpi=80,facecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to adata for processing\n",
    "adata = sc.AnnData(ex_matrix)\n",
    "gene_symbols = ex_matrix.columns\n",
    "\n",
    "#Set the varname to gene_symbols\n",
    "adata.var['gene_symbols'] = gene_symbols\n",
    "adata.var_names_make_unique()\n",
    "adata # returns shape (cellsXgenes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** At this point, we begin pySCENIC steps. For this workflow, we run the first two steps of pySCENIC (grn, and ctx) via CLI commands submitted as an sbatch script. See **run_grn_nodask.sh** and **run_ctx.sh**.\n",
    "\n",
    " The first slurm script for inferring the gene regulatory network has an approximate runtime of 24-28 hours per 10,000 cells with a depth of approximately 6,000 Genes/Cell, given the default resources allocated in the configuration. The second step, ctx, doesn't take as long - however, we ran each step except for aucell (3rd and final step) as sbatch jobs. \n",
    "\n",
    " **NOTE:** If your single cell expression matrix is sparse (likely), then you should opt for the '--sparse' argument for the GRN step, it significantly reduces the runtime of this step. \n",
    "\n",
    "\n",
    "The GRN step will produce a csv of adjacensies. Consisting of transcription factors, and corresponding target genes. The importance column is a measure of impact. The higher the importance of a transcription factor to the target gene, the more regulative power it has over it. This is simply an overlapping of the genes present in your given expression matrix, and known transcription factors for your target organism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the adjacencies file created from the grn step. \n",
    "adjacencies = pd.read_csv(ADJACENCIES_FNAME, index_col=False, sep=',')\n",
    "adjacencies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we examine the output from the ctx step, which performs motif enrichment on the transcription factors in our data. This creates profiles of genes which are targetted by transcription factors, quantifying the importance with parameters like AUC and motifsimilarity. We will use this information to compile regulons within the data. By using this information, we generate 'regulons' , consisting of genes which regulate one another surrounding a central target gene. The regulon object generated below consists of target genes, and weights per transcription factor. This will act as the input for the final step, aucell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regulon csv needed some reformatting in my case to deal with multi-indexing with TF/MotifID\n",
    "from pyscenic.utils import load_motifs\n",
    "import operator as op\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "BASE_URL = \"http://motifcollections.aertslab.org/v9/logos/\"\n",
    "COLUMN_NAME_LOGO = \"MotifLogo\"\n",
    "COLUMN_NAME_MOTIF_ID = \"MotifID\"\n",
    "COLUMN_NAME_TARGETS = \"TargetGenes\"\n",
    "\n",
    "def display_logos(df: pd.DataFrame, top_target_genes: int = 3, base_url: str = BASE_URL):\n",
    "    \"\"\"\n",
    "    :param df:\n",
    "    :param base_url:\n",
    "    \"\"\"\n",
    "    # Make sure the original dataframe is not altered.\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Add column with URLs to sequence logo.\n",
    "    def create_url(motif_id):\n",
    "        return '<img src=\"{}{}.png\" style=\"max-height:124px;\"></img>'.format(base_url, motif_id)\n",
    "    df[(\"Enrichment\", COLUMN_NAME_LOGO)] = list(map(create_url, df.index.get_level_values(COLUMN_NAME_MOTIF_ID)))\n",
    "    \n",
    "    # Truncate TargetGenes.\n",
    "    def truncate(col_val):\n",
    "        return sorted(col_val, key=op.itemgetter(1))[:top_target_genes]\n",
    "    df[(\"Enrichment\", COLUMN_NAME_TARGETS)] = list(map(truncate, df[(\"Enrichment\", COLUMN_NAME_TARGETS)]))\n",
    "    \n",
    "    MAX_COL_WIDTH = pd.get_option('display.max_colwidth')\n",
    "    pd.set_option('display.max_colwidth', 200)\n",
    "    display(HTML(df.head().to_html(escape=False)))\n",
    "    pd.set_option('display.max_colwidth', MAX_COL_WIDTH)\n",
    "\n",
    "reg = pd.read_csv(REGULONS_FNAME, sep=',',index_col=False,header=1)\n",
    "reg = reg.rename(columns={'Unnamed: 0': 'TF','Unnamed: 1':'MotifID'})\n",
    "reg = reg.drop(0)\n",
    "reg = reg.set_index(['TF','MotifID'])\n",
    "reg['TargetGenes'] = reg['TargetGenes'].astype('object')\n",
    "reg.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the datatypes for each column, if any of the objects are labeled as str, convert to objects. This is just a sanity check.\n",
    "print(reg.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add motif metadata to the dataframe \n",
    "df_motifs = load_motifs(REGULONS_FNAME)\n",
    "\n",
    "# If you want, you can examine data for a specific transcription factor.\n",
    "selected_motifs = ['...']\n",
    "df_motifs_sel = df_motifs.iloc[ [ True if x in selected_motifs else False for x in df_motifs.index.get_level_values('TF') ] ,:]\n",
    "display_logos( df_motifs_sel.sort_values([('Enrichment','NES')], ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe to a sequence of regulons. \n",
    "regulons = df2regulons(df_motifs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the last step of pySCENIC, we run AUCell. This will calculate regulon module scores for each cell in our data. Essentially, this measures regulon activity per cell so we can get an idea of the regulatory systems interacting within it. Think of it as a metric of regulon enrichment. The higher the AUCell metric, the more enriched a regulon is within the cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run aucell, this may take a few minutes. For 50,000 cells and 30,000 genes it took ~  5 minutes\n",
    "auc_mtx = aucell(ex_matrix, regulons, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Aucell Matrix. This shows regulon enrichment per cell across all cells/regulons identified in your data. Rows should be cells, columns should be regulons.\n",
    "auc_mtx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also binarize this matrix to represent regulon activation per cell. This step uses the binarize function from pySCENIC , and does a per regulon calculation of bimodal distributions to set an automated custom threshold to determine what 'activated' vs. 'deactivated' looks like in terms of AUCell scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarization function fits a bimodal distribution per regulon across all of its enrichment scores, using this as a threshold for determining activation state. This may take a few minutes.\n",
    "from pyscenic.binarization import binarize\n",
    "bin_auc = binarize(auc_mtx=auc_mtx, num_workers=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the binarized matrix doesn't resemble the structure of the non-binarized (Which resembles a pandas dataframe) , run the following one-liner. \n",
    "#bin_auc = bin_auc[0]\n",
    "bin_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can subset the auc matrices based on the experimental conditions we're dealing with.\n",
    "# NOTE: I provide an example one liner of how this is done, use it as a template for the conditions you're dealing with. \n",
    "\n",
    "# Subset by generic condition\n",
    "Ctrl_auc = auc_mtx[auc_mtx.index.str.contains('Ctrl')]\n",
    "Ctrl_bin_auc = bin_auc[bin_auc.index.str.contains('Ctrl')]\n",
    "\n",
    "stim_auc = auc_mtx[auc_mtx.index.str.contains('stim')]\n",
    "stim_bin_auc = bin_auc[bin_auc.index.str.contains('stim')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's briefly visualize the normal and binarized AUCell matrices via clustermaps. These will hierarchically cluster cells based on regulon enrichment or activation. (Cells on Y axis, regulons on X axis)\n",
    "sns.clustermap(bin_auc,figsize=(12,12))\n",
    "sns.clustermap(auc_mtx, figsize=(12,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_enrichment = auc_mtx.mean().to_dict()\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.hist(average_enrichment.keys(), weights=average_enrichment.values())\n",
    "plt.xticks(rotation = 45)\n",
    "plt.title('Average Regulon Enrichment Across All Cells')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining several subset dictionaries into a dataframe for visualization.\n",
    "average_enrichment_1 = auc_mtx[auc_mtx.index.str.contains('Day1')].mean().to_dict()\n",
    "average_enrichment_2 = auc_mtx[auc_mtx.index.str.contains('Day2')].mean().to_dict()\n",
    "average_enrichment_3 = auc_mtx[auc_mtx.index.str.contains('Day3')].mean().to_dict()\n",
    "dicts = [average_enrichment_1,average_enrichment_2,average_enrichment_3]\n",
    "\n",
    "avg_enrichment_by_age = pd.DataFrame.from_dict(dicts).transpose()\n",
    "new_column_names = ['Day1','Day2','Day3']\n",
    "avg_enrichment_by_age.columns = new_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_enrichment_by_age.plot(kind='bar', stacked=True,figsize=(20,8))\n",
    "plt.xticks(rotation = 45)\n",
    "plt.title('Average Regulon Enrichment Over 3 Days')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line graph depiction of enrichment change over time, given a regulon of interest.\n",
    "plt.figure(figsize=(23,8))\n",
    "plt.plot(avg_enrichment_by_age[['REGULON OF INTEREST']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this next section, we will integrate the pySCENIC AUC matrix data with our initial adata object containing single cell expression data, along with any relevant metadata that we wish to investigate. In the case of this workflow, there are three primary variables. (age, odor exposure, and genotype) This may differ depending on use-case, so this will be one of the few code-chunks that will likely be changed. I also recommend at least having the \"source\" variable if you are working with a merged object. In this case, it is likely your cell IDs have been tagged with their sample metadata, if the data was initially merged as a Seurat object. We rely on this cell ID nomenclature to extract this information on a per-cell basis, ensuring accuracy. \n",
    "\n",
    "NOTE: If this is not the case in a particular dataset, the index 'grep' strategy employed below will not work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty metadata columns\n",
    "adata.obs['age'] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create obs columns for experimental variables\n",
    "def obs_from_str(data, string, colname):\n",
    "    'Look for particular string in the index (Cell IDs) of adata, and assigns string to corresponding value in obs column'\n",
    "    matches = data.obs.index.str.contains(string)\n",
    "    data.obs.loc[matches,colname] = string\n",
    "    return data\n",
    "\n",
    "obs_from_str(adata,'Day1',colname='age')\n",
    "obs_from_str(adata,'Day2',colname='age')\n",
    "obs_from_str(adata,'Day3',colname='age')\n",
    "\n",
    "\n",
    "adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can subset TF motif table based on TF of interest. This is the data used to generate regulon object later on.\n",
    "selected_motifs = ['TF OF INTEREST']\n",
    "df_motifs_sel = df_motifs.iloc[ [ True if x in selected_motifs else False for x in df_motifs.index.get_level_values('TF') ] ,:]\n",
    "display_logos( df_motifs_sel.sort_values([('Enrichment','NES')], ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = 'TF OF INTEREST'\n",
    "\n",
    "#Basically doing ctx step of pySCENIC CLI. Doesn't take too long, however.  \n",
    "modules = list(modules_from_adjacencies(adjacencies,ex_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index(regulon_list, regulon):\n",
    "    'Find the index of regulons list that has the desired regulon of interest'\n",
    "    found_index = -1\n",
    "    for i, entry in enumerate(regulon_list):\n",
    "        if regulon in str(entry):\n",
    "            found_index == i\n",
    "    return found_index\n",
    "   \n",
    "\n",
    "tf_mods = [ x for x in modules if x.transcription_factor==tf ]\n",
    "find_index(regulon_list=regulons, regulon=\"REGULON OF INTEREST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure out where the regulon is in the regulons object\n",
    "for i,entry in enumerate(regulons):\n",
    "    if regulons[i].name == 'REGULON OF INTEREST': # Change this depending on regulon of interest\n",
    "        print(f'REGULON OF INTEREST regulon is at index {i}')\n",
    "        index = i \n",
    "#Extract how many genes are in the regulon, and modules.\n",
    "for i,mod in enumerate( tf_mods ):\n",
    "    print( f'{tf} module {str(i)}: {len(mod.genes)} genes' )\n",
    "print( f'{tf} regulon: {len(regulons[index])} genes' )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can extract this information to a text file for further analysis.\n",
    "for i,mod in enumerate( tf_mods ):\n",
    "    with open( tf+'_module_'+str(i)+'.txt', 'w') as f:\n",
    "        for item in mod.genes:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "with open( tf+'_regulon.txt', 'w') as f:\n",
    "    for item in regulons[index].gene2weight:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining workflow will be heavily custom depending on the goal of the analysis. However, a good first step for this analysis is to integrate your pySCENIC data with your adata object from Scanpy. This will be necessary in most cases, allowing you to see regulon enrichment across cell types, project enrichment in UMAP space, see regulon specificity per cell type, and much more. Here is some example code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrating pySCENIC data with adata.\n",
    "from pyscenic.export import add_scenic_metadata\n",
    "\n",
    "add_scenic_metadata(adata, auc_mtx, regulons)\n",
    "\n",
    "#NOTE: You can rerun this to add the binarized auc_mtx as an additional layer. In my case the binary regulon columns are indicated with a '_y' following the name of the regulon. This may not always be the case!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regulon Specificity scores by celltype. Must have annotated cells.\n",
    "from pyscenic.rss import regulon_specificity_scores\n",
    "from pyscenic.plotting import plot_rss\n",
    "from adjustText import adjust_text\n",
    "\n",
    "rss_cellType = regulon_specificity_scores(auc_mtx=auc_mtx, cell_type_series=adata.obs['celltype'])\n",
    "\n",
    "cats = sorted(list(set(adata.obs['celltype'])))\n",
    "\n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "for c,num in zip(cats, range(1,len(cats)+1)):\n",
    "    x=rss_cellType.T[c]\n",
    "    ax = fig.add_subplot(3,5,num)\n",
    "    plot_rss(rss_cellType, c, top_n=5, max_n=None, ax=ax)\n",
    "    ax.set_ylim( x.min()-(x.max()-x.min())*0.05 , x.max()+(x.max()-x.min())*0.05 )\n",
    "    for t in ax.texts:\n",
    "        t.set_fontsize(12)\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xlabel('')\n",
    "    adjust_text(ax.texts, autoalign='xy', ha='right', va='bottom', arrowprops=dict(arrowstyle='-',color='lightgrey'), precision=0.001 )\n",
    " \n",
    "fig.text(0.5, 0.0, 'Top Regulons per CellType: All Cells', ha='center', va='center', size='x-large')\n",
    "fig.text(0.00, 0.5, 'Regulon specificity score (RSS)', ha='center', va='center', rotation='vertical', size='x-large')\n",
    "plt.tight_layout()\n",
    "plt.rcParams.update({\n",
    "    'figure.autolayout': True,\n",
    "        'figure.titlesize': 'large' ,\n",
    "        'axes.labelsize': 'medium',\n",
    "        'axes.titlesize':'large',\n",
    "        'xtick.labelsize':'medium',\n",
    "        'ytick.labelsize':'medium'\n",
    "        })\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting the auc mtx based on top regulons per cell type, and visualizing this in a clustermap\n",
    "topreg = []\n",
    "for i,c in enumerate(cats):\n",
    "    topreg.extend(\n",
    "        list(rss_cellType.T[c].sort_values(ascending=False)[:5].index)\n",
    "    )\n",
    "topreg = list(set(topreg))\n",
    "\n",
    "auc_mtx_Z = pd.DataFrame( index=auc_mtx.index )\n",
    "for col in list(auc_mtx.columns):\n",
    "    auc_mtx_Z[ col ] = ( auc_mtx[col] - auc_mtx[col].mean()) / auc_mtx[col].std(ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the colormap for celltypes on y axis.\n",
    "def palplot(pal, names, colors=None, size=1):\n",
    "    n = len(pal)\n",
    "    f, ax = plt.subplots(1, 1, figsize=(n * size, size))\n",
    "    ax.imshow(np.arange(n).reshape(1, n),\n",
    "              cmap=mpl.colors.ListedColormap(list(pal)),\n",
    "              interpolation=\"nearest\", aspect=\"auto\")\n",
    "    ax.set_xticks(np.arange(n) - .5)\n",
    "    ax.set_yticks([-.5, .5])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    colors = n * ['k'] if colors is None else colors\n",
    "    for idx, (name, color) in enumerate(zip(names, colors)):\n",
    "        ax.text(0.0+idx, 0.0, name, color=color, horizontalalignment='center', verticalalignment='center')\n",
    "    return f\n",
    "colors = sns.color_palette('bright',n_colors=len(cats) )\n",
    "colorsd = dict( zip( cats, colors ))\n",
    "colormap = [ colorsd[x] for x in adata.obs['celltype'] ]\n",
    "\n",
    "sns.set()\n",
    "sns.set(font_scale=0.8)\n",
    "fig = palplot( colors, cats, size=1.0)\n",
    "\n",
    "handles = [Patch(facecolor=colorsd[name]) for name in colorsd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the clustermap\n",
    "sns.set(font_scale=1.2)\n",
    "g = sns.clustermap(auc_mtx_Z[topreg], annot=False,  square=False,  linecolor='gray',\n",
    "    yticklabels=False, xticklabels=True, vmin=-2, vmax=6, row_colors=colormap,\n",
    "    cmap=\"YlGnBu\", figsize=(21,16) )\n",
    "g.cax.set_visible(True)\n",
    "g.ax_heatmap.set_ylabel('')\n",
    "g.ax_heatmap.set_xlabel('')\n",
    "plt.legend(handles,colorsd,title ='Cell Type', bbox_to_anchor =(1, 1), bbox_transform=plt.gcf().transFigure,loc = 'center left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Enrichment in UMAP space (Uses nonbinarized aucell matrix in integrated adata)\n",
    "sc.pl.umap(adata=adata,color='Regulon(REGULON)',ax= axs[1,0], show=False, color_map='plasma',title=\"Regulon of interest Enrichment Across all Cells\")\n",
    "\n",
    "# Plotting activation in UMAP space (Uses binarized aucell matrix in integrated adata)\n",
    "sc.pl.umap(adata=adata,color='Regulon(REGULON)_y',ax= axs[1,1],show=False,color_map='Spectral_r', title=\"Regulon of interest Activation Across all Cells\")\n",
    "\n",
    "# NOTE: The activation umap implies the '_y' nomenclature mentioned prior, if yours is different then change accordingly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Further Reading:** This workflow is based off a combination of established workflows provided by SCENIC/pySCENIC authors. Check them out if you want a starting place to potentially improve this downstream workflow.\n",
    "\n",
    "- https://htmlpreview.github.io/?https://github.com/aertslab/SCENICprotocol/blob/master/notebooks/PBMC10k_downstream-analysis.html\n",
    "- https://github.com/aertslab/SCENICprotocol/blob/master/notebooks/SCENIC%20Protocol%20-%20Case%20study%20-%20Mouse%20brain%20data%20set.ipynb\n",
    "- https://github.com/hbc/knowledgebase/blob/master/scrnaseq/pySCENIC.md (For CLI guidance)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
